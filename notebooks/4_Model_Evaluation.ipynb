{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook provides a detailed evaluation of our trained cryptocurrency prediction model.\n",
    "\n",
    "## Contents\n",
    "1. Load Model and Data\n",
    "2. Performance Metrics\n",
    "3. Prediction Analysis\n",
    "4. Error Analysis\n",
    "5. Trading Performance\n",
    "6. Model Robustness Tests\n"
   ],
   "id": "d4faf7b262cc6dc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Import our custom modules\n",
    "from src.training.model import CryptoPredictor\n",
    "from src.preprocessing.pipeline import Pipeline\n",
    "from src.visualization.visualizer import CryptoVisualizer\n"
   ],
   "id": "66bfe65dc032e6be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Load Model and Data\n",
   "id": "6b2339809577453c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the best model from previous experiments\n",
    "model = CryptoPredictor.load('models/best_model.h5')\n",
    "\n",
    "# Load test data\n",
    "pipeline = Pipeline()\n",
    "test_data = pd.read_csv('data/processed/test_data.csv', index_col='timestamp', parse_dates=True)\n",
    "test_sequences = pipeline.prepare_sequences(test_data)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(test_sequences['X_test'])\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "predictions_original = pipeline.inverse_transform(predictions)\n",
    "actual_original = pipeline.inverse_transform(test_sequences['y_test'])\n"
   ],
   "id": "5b5d75d6e39e5883"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Performance Metrics\n",
   "id": "efc90c111c33c80f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate various performance metrics\"\"\"\n",
    "    metrics = {\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'MAPE': np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    }\n",
    "    \n",
    "    # Directional accuracy\n",
    "    direction_true = np.sign(np.diff(y_true))\n",
    "    direction_pred = np.sign(np.diff(y_pred))\n",
    "    metrics['Directional Accuracy'] = np.mean(direction_true == direction_pred) * 100\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "metrics = calculate_metrics(actual_original, predictions_original)\n",
    "pd.DataFrame(metrics, index=['Value']).T\n"
   ],
   "id": "46ec89712e814610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Prediction Analysis\n",
   "id": "d116cdbd6a6061b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def analyze_predictions():\n",
    "    \"\"\"Create detailed prediction analysis plots\"\"\"\n",
    "    # Time series plot\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                        subplot_titles=('Price Predictions', 'Prediction Error'))\n",
    "    \n",
    "    # Actual vs Predicted\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=actual_original, name='Actual', line=dict(color='blue')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=predictions_original, name='Predicted', line=dict(color='red')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Error plot\n",
    "    errors = predictions_original - actual_original\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=errors, name='Error', line=dict(color='green')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=800, title='Prediction Analysis')\n",
    "    return fig\n",
    "\n",
    "fig = analyze_predictions()\n",
    "fig.show()\n"
   ],
   "id": "e24c4ceddd382104"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Error Analysis\n",
   "id": "c71273b713e14fa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def analyze_errors():\n",
    "    \"\"\"Analyze prediction errors in detail\"\"\"\n",
    "    errors = predictions_original - actual_original\n",
    "    \n",
    "    # Error distribution\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    sns.histplot(errors, kde=True)\n",
    "    plt.title('Error Distribution')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    sns.scatterplot(x=actual_original, y=errors)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Errors vs Actual Values')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Error statistics\n",
    "    error_stats = pd.Series({\n",
    "        'Mean Error': np.mean(errors),\n",
    "        'Std Error': np.std(errors),\n",
    "        'Max Error': np.max(errors),\n",
    "        'Min Error': np.min(errors),\n",
    "        'Skewness': pd.Series(errors).skew(),\n",
    "        'Kurtosis': pd.Series(errors).kurtosis()\n",
    "    })\n",
    "    \n",
    "    return error_stats\n",
    "\n",
    "error_stats = analyze_errors()\n",
    "print(\"\\nError Statistics:\")\n",
    "print(error_stats)\n"
   ],
   "id": "5a1de572e6488af8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Trading Performance\n",
   "id": "7747da14dfe41035"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_trading_performance():\n",
    "    \"\"\"Evaluate model performance in trading context\"\"\"\n",
    "    # Calculate returns\n",
    "    actual_returns = np.diff(actual_original) / actual_original[:-1]\n",
    "    pred_returns = np.diff(predictions_original) / predictions_original[:-1]\n",
    "    \n",
    "    # Trading signals (1: buy, -1: sell, 0: hold)\n",
    "    signals = np.sign(pred_returns)\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    strategy_returns = signals[:-1] * actual_returns[1:]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    trading_metrics = {\n",
    "        'Total Return': np.sum(strategy_returns),\n",
    "        'Annualized Return': np.mean(strategy_returns) * 252,\n",
    "        'Sharpe Ratio': np.mean(strategy_returns) / np.std(strategy_returns) * np.sqrt(252),\n",
    "        'Win Rate': np.mean(strategy_returns > 0) * 100,\n",
    "        'Max Drawdown': np.min(np.maximum.accumulate(strategy_returns) - strategy_returns)\n",
    "    }\n",
    "    \n",
    "    # Plot cumulative returns\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(np.cumprod(1 + strategy_returns) - 1, label='Strategy')\n",
    "    plt.plot(np.cumprod(1 + actual_returns[1:]) - 1, label='Buy & Hold')\n",
    "    plt.title('Cumulative Returns')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.Series(trading_metrics)\n",
    "\n",
    "trading_metrics = evaluate_trading_performance()\n",
    "print(\"\\nTrading Performance Metrics:\")\n",
    "print(trading_metrics)\n"
   ],
   "id": "15626c2a19b1cd77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Model Robustness Tests\n",
   "id": "e7bc4a422923dea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test_model_robustness():\n",
    "    \"\"\"Test model performance under different conditions\"\"\"\n",
    "    robustness_tests = {}\n",
    "    \n",
    "    # Test with different market conditions\n",
    "    returns = np.diff(actual_original) / actual_original[:-1]\n",
    "    volatility = pd.Series(returns).rolling(20).std()\n",
    "    \n",
    "    # High volatility periods\n",
    "    high_vol_mask = volatility > volatility.median()\n",
    "    high_vol_metrics = calculate_metrics(\n",
    "        actual_original[high_vol_mask],\n",
    "        predictions_original[high_vol_mask]\n",
    "    )\n",
    "    robustness_tests['High Volatility'] = high_vol_metrics\n",
    "    \n",
    "    # Low volatility periods\n",
    "    low_vol_mask = volatility <= volatility.median()\n",
    "    low_vol_metrics = calculate_metrics(\n",
    "        actual_original[low_vol_mask],\n",
    "        predictions_original[low_vol_mask]\n",
    "    )\n",
    "    robustness_tests['Low Volatility'] = low_vol_metrics\n",
    "    \n",
    "    # Up trend vs Down trend\n",
    "    trend = pd.Series(actual_original).rolling(20).mean().diff()\n",
    "    \n",
    "    up_trend_mask = trend > 0\n",
    "    up_trend_metrics = calculate_metrics(\n",
    "        actual_original[up_trend_mask],\n",
    "        predictions_original[up_trend_mask]\n",
    "    )\n",
    "    robustness_tests['Up Trend'] = up_trend_metrics\n",
    "    \n",
    "    down_trend_mask = trend <= 0\n",
    "    down_trend_metrics = calculate_metrics(\n",
    "        actual_original[down_trend_mask],\n",
    "        predictions_original[down_trend_mask]\n",
    "    )\n",
    "    robustness_tests['Down Trend'] = down_trend_metrics\n",
    "    \n",
    "    return pd.DataFrame(robustness_tests)\n",
    "\n",
    "robustness_results = test_model_robustness()\n",
    "print(\"\\nRobustness Test Results:\")\n",
    "print(robustness_results)\n"
   ],
   "id": "f3a86dedb8b21310"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
