{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54328b7e-0eb6-44d9-8ac5-13919ea28501",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Model Experimentation\n",
    "\n",
    "This notebook explores different model architectures and performs hyperparameter tuning.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Data Preparation\n",
    "2. Baseline Model\n",
    "3. Architecture Exploration\n",
    "4. Hyperparameter Tuning\n",
    "5. Model Comparison\n",
    "6. Final Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12831e-b07c-492d-b5b3-8c26609af42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import our custom modules\n",
    "from src.training.model import CryptoPredictor\n",
    "from src.preprocessing.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b95b8-7246-47f1-8554-27dac459a32c",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2794a3b2-397a-4cef-b053-52f6cc1d0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed features from previous notebook\n",
    "processed_data = pd.read_csv('data/processed/features_engineered.csv', index_col='timestamp', parse_dates=True)\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = Pipeline(\n",
    "    sequence_length=60,\n",
    "    prediction_length=1\n",
    ")\n",
    "\n",
    "# Prepare sequences\n",
    "result = pipeline.run(processed_data)\n",
    "\n",
    "print(\"Training data shape:\", result['X_train'].shape)\n",
    "print(\"Validation data shape:\", result['X_val'].shape)\n",
    "print(\"Test data shape:\", result['X_test'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d714b-186f-4537-938c-4b1cc81ad1a0",
   "metadata": {},
   "source": [
    "## 2. Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4ffd6-022b-4281-aeca-60ac68eedc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(input_shape):\n",
    "    \"\"\"Create a simple baseline LSTM model\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train baseline model\n",
    "baseline_model = create_baseline_model((result['X_train'].shape[1], result['X_train'].shape[2]))\n",
    "baseline_history = baseline_model.fit(\n",
    "    result['X_train'],\n",
    "    result['y_train'],\n",
    "    validation_data=(result['X_val'], result['y_val']),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=baseline_history.history['loss'], name='Training Loss'))\n",
    "fig.add_trace(go.Scatter(y=baseline_history.history['val_loss'], name='Validation Loss'))\n",
    "fig.update_layout(title='Baseline Model Training History')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cb160-6a9f-4b1b-9c19-cbe426a1a59a",
   "metadata": {},
   "source": [
    "## 3. Architecture Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db665bf-20e5-4205-a8a5-bce48d6b6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_architectures():\n",
    "    \"\"\"Test different model architectures\"\"\"\n",
    "    architectures = {\n",
    "        'single_lstm': CryptoPredictor(\n",
    "            input_shape=(60, result['X_train'].shape[2]),\n",
    "            lstm_units=[64],\n",
    "            dropout_rate=0.2\n",
    "        ),\n",
    "        'stacked_lstm': CryptoPredictor(\n",
    "            input_shape=(60, result['X_train'].shape[2]),\n",
    "            lstm_units=[64, 32],\n",
    "            dropout_rate=0.2\n",
    "        ),\n",
    "        'lstm_with_bn': CryptoPredictor(\n",
    "            input_shape=(60, result['X_train'].shape[2]),\n",
    "            lstm_units=[64, 32],\n",
    "            dropout_rate=0.2,\n",
    "            use_batch_norm=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in architectures.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.build()\n",
    "        model.compile()\n",
    "        \n",
    "        history = model.fit(\n",
    "            result['X_train'],\n",
    "            result['y_train'],\n",
    "            validation_data=(result['X_val'], result['y_val']),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[EarlyStopping(patience=5)]\n",
    "        )\n",
    "        \n",
    "        results[name] = {\n",
    "            'history': history.history,\n",
    "            'model': model\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "architecture_results = experiment_architectures()\n",
    "\n",
    "# Plot comparison\n",
    "fig = go.Figure()\n",
    "for name, result in architecture_results.items():\n",
    "    fig.add_trace(go.Scatter(y=result['history']['val_loss'], name=f'{name} Val Loss'))\n",
    "fig.update_layout(title='Architecture Comparison')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ffc7f-dabf-4927-b8df-16fd10807fdd",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16edbac-4cd2-48fa-8d8a-943d545ffb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def tune_hyperparameters():\n",
    "    \"\"\"Perform grid search for hyperparameters\"\"\"\n",
    "    param_grid = {\n",
    "        'lstm_units': [[32], [64], [128], [64, 32], [128, 64]],\n",
    "        'dropout_rate': [0.1, 0.2, 0.3],\n",
    "        'learning_rate': [0.001, 0.0005, 0.0001]\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTesting parameters: {params}\")\n",
    "        \n",
    "        model = CryptoPredictor(\n",
    "            input_shape=(60, result['X_train'].shape[2]),\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        model.build()\n",
    "        model.compile()\n",
    "        \n",
    "        history = model.fit(\n",
    "            result['X_train'],\n",
    "            result['y_train'],\n",
    "            validation_data=(result['X_val'], result['y_val']),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=[EarlyStopping(patience=5)]\n",
    "        )\n",
    "        \n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'best_val_loss': best_val_loss\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('best_val_loss')\n",
    "\n",
    "tuning_results = tune_hyperparameters()\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "tuning_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0dd2b-079a-47d0-86f2-9d9606ad2f98",
   "metadata": {},
   "source": [
    "## 5. Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbdb0a-3188-4502-bdf1-151ab523a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def compare_models(baseline_history, architecture_results, best_tuned_model):\n",
    "    \"\"\"Compare all model variants\"\"\"\n",
    "    comparison_metrics = pd.DataFrame()\n",
    "    \n",
    "    # Add baseline results\n",
    "    comparison_metrics.loc['baseline', 'val_loss'] = min(baseline_history.history['val_loss'])\n",
    "    \n",
    "    # Add architecture results\n",
    "    for name, result in architecture_results.items():\n",
    "        comparison_metrics.loc[name, 'val_loss'] = min(result['history']['val_loss'])\n",
    "    \n",
    "    # Add best tuned model\n",
    "    comparison_metrics.loc['tuned', 'val_loss'] = best_tuned_model['best_val_loss']\n",
    "    \n",
    "    return comparison_metrics\n",
    "\n",
    "comparison = compare_models(\n",
    "    baseline_history,\n",
    "    architecture_results,\n",
    "    tuning_results.iloc[0]\n",
    ")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "comparison['val_loss'].plot(kind='bar')\n",
    "plt.title('Model Comparison')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091359fc-0bd5-4b5b-b15f-ac2b63920090",
   "metadata": {},
   "source": [
    "## 6. Final Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9e413-e098-473b-9dbb-75997ac551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final model with best parameters\n",
    "best_params = tuning_results.iloc[0]['params']\n",
    "final_model = CryptoPredictor(\n",
    "    input_shape=(60, result['X_train'].shape[2]),\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "final_model.build()\n",
    "final_model.compile()\n",
    "\n",
    "# Train final model\n",
    "final_history = final_model.fit(\n",
    "    result['X_train'],\n",
    "    result['y_train'],\n",
    "    validation_data=(result['X_val'], result['y_val']),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10),\n",
    "        ModelCheckpoint('models/best_model.h5', save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save model architecture and hyperparameters\n",
    "model_config = {\n",
    "    'architecture': best_params,\n",
    "    'training_params': {\n",
    "        'batch_size': 32,\n",
    "        'initial_epochs': 100,\n",
    "        'early_stopping_patience': 10\n",
    "    },\n",
    "    'performance': {\n",
    "        'best_val_loss': min(final_history.history['val_loss'])\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('models/model_config.json', 'w') as f:\n",
    "    json.dump(model_config, f, indent=4)\n",
    "\n",
    "print(\"Final model saved with configuration\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
